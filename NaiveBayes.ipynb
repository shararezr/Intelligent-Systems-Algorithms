{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv(\"income_Q5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Because about three-quarters of the available data is in Class \"income = <=50K\", the data is not well distributed and causes errors. To avoid this problem, we select the data in such a way that the number of two types of classes for the \"income\" feature is approximately equal. Once I tried with all the data, it just had good accuracy and the rest of the criteria (Precision,Recall,F1_Score) were all zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>&lt;=38</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7961</th>\n",
       "      <td>&lt;=38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>&gt;38</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45683</th>\n",
       "      <td>&gt;38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29514</th>\n",
       "      <td>&gt;38</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34797</th>\n",
       "      <td>&lt;=38</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>&lt;=9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>&gt;38</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28443</th>\n",
       "      <td>&lt;=38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>&lt;=9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>&lt;=38</td>\n",
       "      <td>Special</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44803</th>\n",
       "      <td>&gt;38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>&gt;9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23374 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         workclass     education educational-num  \\\n",
       "2552   <=38  Self-emp-not-inc     Bachelors              >9   \n",
       "7961   <=38           Private  Some-college              >9   \n",
       "6695    >38         State-gov     Doctorate              >9   \n",
       "45683   >38           Private     Assoc-voc              >9   \n",
       "29514   >38       Federal-gov       Masters              >9   \n",
       "...     ...               ...           ...             ...   \n",
       "34797  <=38           Private          11th             <=9   \n",
       "23484   >38  Self-emp-not-inc   Prof-school              >9   \n",
       "28443  <=38           Private       HS-grad             <=9   \n",
       "9137   <=38           Special  Some-college              >9   \n",
       "44803   >38           Private  Some-college              >9   \n",
       "\n",
       "           marital-status       occupation   relationship   race  gender  \\\n",
       "2552   Married-civ-spouse            Sales           Wife  White  Female   \n",
       "7961             Divorced     Adm-clerical      Own-child  White    Male   \n",
       "6695              Widowed   Prof-specialty  Not-in-family  Black    Male   \n",
       "45683             Widowed            Sales  Not-in-family  White  Female   \n",
       "29514  Married-civ-spouse   Prof-specialty        Husband  White    Male   \n",
       "...                   ...              ...            ...    ...     ...   \n",
       "34797       Never-married    Other-service      Own-child  White    Male   \n",
       "23484  Married-civ-spouse   Prof-specialty        Husband  White    Male   \n",
       "28443            Divorced  Exec-managerial      Unmarried  White  Female   \n",
       "9137        Never-married                ?      Own-child  White    Male   \n",
       "44803  Married-civ-spouse   Prof-specialty        Husband  White    Male   \n",
       "\n",
       "      native-country income  \n",
       "2552   United-States   >50K  \n",
       "7961   United-States  <=50K  \n",
       "6695   United-States   >50K  \n",
       "45683  United-States  <=50K  \n",
       "29514  United-States   >50K  \n",
       "...              ...    ...  \n",
       "34797  United-States  <=50K  \n",
       "23484  United-States   >50K  \n",
       "28443  United-States   >50K  \n",
       "9137   United-States  <=50K  \n",
       "44803  United-States   >50K  \n",
       "\n",
       "[23374 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data['income'].unique()\n",
    "df1=data[data['income'] == a[0]]\n",
    "df2=data[data['income'] == a[1]]\n",
    "index = list(df1.index.values.astype(int))\n",
    "samples = random.sample(index,df2.shape[0])\n",
    "df3 = data.loc[samples,:]\n",
    "df = pd.concat([df2, df3])\n",
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(df,per):\n",
    "    #first Replace them!\n",
    "    data = df.sample(frac=1)\n",
    "    percent = int(data.shape[0]*per/100)\n",
    "    X_train = data.iloc[0:percent,:]\n",
    "    X_test = data.iloc[percent:-1,:]\n",
    "    return X_train,X_test\n",
    "    \n",
    "def NaiveBayes(data):\n",
    "\n",
    "    df = data\n",
    "    columns = list(df.columns)\n",
    "    columns.pop()\n",
    "    df['labels'] = -1\n",
    "    tag = list(df['income'].unique())\n",
    "    #one hot coded\n",
    "    df.loc[df['income'] == tag[0],'labels'] = 0\n",
    "    df.loc[df['income'] == tag[1],'labels'] = 1\n",
    "    \n",
    "    #split data\n",
    "    X_train,X_test = cross_validation(df,80)\n",
    "    tag = list(X_train['labels'].unique())\n",
    "    X_test['y_predict'] = -1\n",
    "     \n",
    "    acc = 0\n",
    "    for row in range(X_test.shape[0]):\n",
    "        #make array of P(X1 | yi)P(X2 | yi)...P(Xn | yi) P(yi)\n",
    "        probXofYs = np.zeros([1,2])\n",
    "        \n",
    "        for l in tag:\n",
    "            probsofXi= 1\n",
    "            \n",
    "            #P(yi)\n",
    "            probYi = X_train[X_train['labels'] == l].shape[0]/X_train.shape[0]\n",
    "\n",
    "            for col in range(X_test.shape[1]-3):\n",
    "                \n",
    "                X = X_test.iloc[row,col]\n",
    "                #Laplace smoothing initialize parameters\n",
    "                v = len(list(df[columns[col]].unique())) \n",
    "                \n",
    "                #compute each P(Xi | yi)\n",
    "                probXi = (X_train[(X_train[columns[col]] == X)].shape[0]+v)/X_train.shape[0]\n",
    "                probXiYi=(X_train[(X_train[columns[col]] == X)&(X_train['labels']==l)].shape[0]+1)/(probYi+v)\n",
    "\n",
    "                #the features are independent from each other\n",
    "                probsofXi = probsofXi*probXiYi\n",
    "            \n",
    "            probXofYs[0,l] = probsofXi*probYi\n",
    "            \n",
    "        X_test.iloc[row,-1] = probXofYs.argmax(axis = 1)\n",
    "        #compute accuracy\n",
    "        if(X_test.iloc[row,-1] == X_test.iloc[row,-2]): acc+=1\n",
    "    \n",
    "    \n",
    "    display(\"Accuracy:\", acc/X_test.shape[0]*100)\n",
    "    Ypredict = np.array(X_test.iloc[:,-1])\n",
    "    Truelabel = np.array(X_test.iloc[:,-2])\n",
    "    return X_test\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_Matrix(X_Test):\n",
    "    cnt_TP = 0\n",
    "    cnt_TN = 0\n",
    "    cnt_FP = 0\n",
    "    cnt_FN = 0\n",
    "    for row in range(X_Test.shape[0]):\n",
    "        if(X_Test.iloc[row,-2] == X_Test.iloc[row,-1]==1):\n",
    "            cnt_TP +=1\n",
    "        if(X_Test.iloc[row,-2] == X_Test.iloc[row,-1]==0):\n",
    "            cnt_TN +=1\n",
    "        if(X_Test.iloc[row,-2] == 1 and X_Test.iloc[row,-1]==0):\n",
    "            cnt_FN +=1\n",
    "        if(X_Test.iloc[row,-2] == 0 and X_Test.iloc[row,-1]==1):\n",
    "            cnt_FP +=1\n",
    "    cm = np.array([cnt_TP, cnt_FN, cnt_FP, cnt_TN]).reshape(2,2)\n",
    "    print(cm)\n",
    "    acc = (cnt_TP+cnt_TN)/X_Test.shape[0]*100\n",
    "    pres = cnt_TP/(cnt_TP+cnt_FP+1)*100\n",
    "    recall = cnt_TP/(cnt_TP+cnt_FN+1)*100\n",
    "    F1 = 2*pres*recall/(pres+recall+1)\n",
    "    classes = ['Positive','Negative']\n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "    cm_frame1 = pd.DataFrame(data=cm,columns=pd.MultiIndex(levels=[['Predicted:'],\\\n",
    "                                                                  classes],codes=level_labels),\\\n",
    "                        index=pd.MultiIndex(levels=[['Actual:'], classes], codes=level_labels))\n",
    "    criteria=pd.DataFrame(data={'Accuracy':acc,'Precision':pres,'Recall':recall,'F1_Score':F1},index=['0'])\n",
    "    return cm_frame1 ,criteria\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "79.0543431750107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = NaiveBayes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1728  588]\n",
      " [ 391 1967]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
       "      <th>Positive</th>\n",
       "      <td>1728</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>391</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted:         \n",
       "                   Positive Negative\n",
       "Actual: Positive       1728      588\n",
       "        Negative        391     1967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.054343</td>\n",
       "      <td>81.509434</td>\n",
       "      <td>74.579197</td>\n",
       "      <td>77.394629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Precision     Recall   F1_Score\n",
       "0  79.054343  81.509434  74.579197  77.394629"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_frame1, criteria = Confusion_Matrix(X_test)\n",
    "display(cm_frame1)\n",
    "display(criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The importance of using Laplace smoothing\n",
    "###### If a given Xi and class never occur together in the training data, then the probability estimate for that Xi conditioned on that class will be zero. Recall, the probability estimate is directly proportional to the number of times a given Xi occurs. Discuss why this scenario is problematic for our classifier and how an adversarial agent (spam generator) might take advantage of it. One solution is to smooth all our word probabilities upwards by a count of 1. That is, we assume we saw each token in each Xi for each class once more than we actually did."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
